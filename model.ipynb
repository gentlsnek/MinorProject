{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Loaded: 3103 samples, 3960 features.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import skfuzzy as fuzz\n",
    "from skfuzzy import control as ctrl\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the dataset\n",
    "file_path = \"augmented_dataset.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Drop package name columns (if any) and select relevant features\n",
    "features_to_drop = [col for col in df.columns if col.startswith(\"package_name_\")]\n",
    "df_cleaned = df.drop(columns=features_to_drop)\n",
    "\n",
    "# Extract labels and features\n",
    "labels = df_cleaned['label'].values\n",
    "features = df_cleaned.drop(columns=['label']).values\n",
    "\n",
    "# Normalize features\n",
    "scaler = MinMaxScaler()\n",
    "features_scaled = scaler.fit_transform(features)\n",
    "\n",
    "# Split dataset into training and testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(features_scaled, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f\"Dataset Loaded: {df_cleaned.shape[0]} samples, {df_cleaned.shape[1]} features.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define fuzzy variables\n",
    "num_permissions = ctrl.Antecedent(np.arange(0, 1.01, 0.01), 'num_permissions')\n",
    "num_services = ctrl.Antecedent(np.arange(0, 1.01, 0.01), 'num_services')\n",
    "file_size = ctrl.Antecedent(np.arange(0, 1.01, 0.01), 'file_size')\n",
    "\n",
    "# Define fuzzy output for classification (Benign, Passive Malware, Active Malware)\n",
    "malware_class = ctrl.Consequent(np.arange(0, 3, 1), 'malware_class')\n",
    "\n",
    "# Define fuzzy membership functions\n",
    "num_permissions['low'] = fuzz.trimf(num_permissions.universe, [0, 0, 0.5])\n",
    "num_permissions['medium'] = fuzz.trimf(num_permissions.universe, [0.2, 0.5, 0.8])\n",
    "num_permissions['high'] = fuzz.trimf(num_permissions.universe, [0.5, 1, 1])\n",
    "\n",
    "num_services['low'] = fuzz.trimf(num_services.universe, [0, 0, 0.5])\n",
    "num_services['medium'] = fuzz.trimf(num_services.universe, [0.2, 0.5, 0.8])\n",
    "num_services['high'] = fuzz.trimf(num_services.universe, [0.5, 1, 1])\n",
    "\n",
    "file_size['small'] = fuzz.trimf(file_size.universe, [0, 0, 0.5])\n",
    "file_size['medium'] = fuzz.trimf(file_size.universe, [0.2, 0.5, 0.8])\n",
    "file_size['large'] = fuzz.trimf(file_size.universe, [0.5, 1, 1])\n",
    "\n",
    "malware_class['benign'] = fuzz.trimf(malware_class.universe, [0, 0, 1])\n",
    "malware_class['passive'] = fuzz.trimf(malware_class.universe, [0, 1, 2])\n",
    "malware_class['active'] = fuzz.trimf(malware_class.universe, [1, 2, 2])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# 3. Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "rule1 = ctrl.Rule(num_permissions['low'] & num_services['low'] & file_size['small'], malware_class['benign'])\n",
    "rule2 = ctrl.Rule(num_permissions['medium'] & num_services['medium'] & file_size['medium'], malware_class['passive'])\n",
    "rule3 = ctrl.Rule(num_permissions['high'] | num_services['high'] | file_size['large'], malware_class['active'])\n",
    "\n",
    "# Create control system\n",
    "malware_ctrl = ctrl.ControlSystem([rule1, rule2, rule3])\n",
    "malware_detector = ctrl.ControlSystemSimulation(malware_ctrl)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Perform classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = []\n",
    "\n",
    "for i in range(len(X_test)):\n",
    "    malware_detector.input['num_permissions'] = X_test[i][0]\n",
    "    malware_detector.input['num_services'] = X_test[i][1]\n",
    "    malware_detector.input['file_size'] = X_test[i][2]\n",
    "    \n",
    "    malware_detector.compute()\n",
    "    \n",
    "    pred = malware_detector.output['malware_class']\n",
    "    predictions.append(round(pred))  # Round to nearest class (0, 1, or 2)\n",
    "\n",
    "# Convert to NumPy array for evaluation\n",
    "predictions = np.array(predictions)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Evaluvate Model and Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Classification metrics can't handle a mix of continuous and multiclass targets",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Calculate accuracy\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m accuracy \u001b[38;5;241m=\u001b[39m \u001b[43maccuracy_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpredictions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel Accuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00maccuracy\u001b[38;5;250m \u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m100\u001b[39m\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Visualizing results\u001b[39;00m\n",
      "File \u001b[0;32m~/projects/MinorProject/provenv/lib/python3.12/site-packages/sklearn/utils/_param_validation.py:216\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    210\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    211\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m    212\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m    213\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m    214\u001b[0m         )\n\u001b[1;32m    215\u001b[0m     ):\n\u001b[0;32m--> 216\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    217\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[1;32m    219\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[1;32m    220\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[1;32m    221\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[1;32m    222\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[1;32m    223\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    224\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    225\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[1;32m    226\u001b[0m     )\n",
      "File \u001b[0;32m~/projects/MinorProject/provenv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:227\u001b[0m, in \u001b[0;36maccuracy_score\u001b[0;34m(y_true, y_pred, normalize, sample_weight)\u001b[0m\n\u001b[1;32m    225\u001b[0m \u001b[38;5;66;03m# Compute accuracy for each possible representation\u001b[39;00m\n\u001b[1;32m    226\u001b[0m y_true, y_pred \u001b[38;5;241m=\u001b[39m attach_unique(y_true, y_pred)\n\u001b[0;32m--> 227\u001b[0m y_type, y_true, y_pred \u001b[38;5;241m=\u001b[39m \u001b[43m_check_targets\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    228\u001b[0m check_consistent_length(y_true, y_pred, sample_weight)\n\u001b[1;32m    230\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y_type\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmultilabel\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[0;32m~/projects/MinorProject/provenv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:107\u001b[0m, in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m    104\u001b[0m     y_type \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmulticlass\u001b[39m\u001b[38;5;124m\"\u001b[39m}\n\u001b[1;32m    106\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(y_type) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m--> 107\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    108\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mClassification metrics can\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt handle a mix of \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m and \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m targets\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m    109\u001b[0m             type_true, type_pred\n\u001b[1;32m    110\u001b[0m         )\n\u001b[1;32m    111\u001b[0m     )\n\u001b[1;32m    113\u001b[0m \u001b[38;5;66;03m# We can't have more than one value on y_type => The set is no more needed\u001b[39;00m\n\u001b[1;32m    114\u001b[0m y_type \u001b[38;5;241m=\u001b[39m y_type\u001b[38;5;241m.\u001b[39mpop()\n",
      "\u001b[0;31mValueError\u001b[0m: Classification metrics can't handle a mix of continuous and multiclass targets"
     ]
    }
   ],
   "source": [
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print(f\"Model Accuracy: {accuracy * 100:.2f}%\")\n",
    "\n",
    "# Visualizing results\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(y_test, predictions, alpha=0.5)\n",
    "plt.xlabel(\"Actual Labels\")\n",
    "plt.ylabel(\"Predicted Labels\")\n",
    "plt.title(\"Actual vs. Predicted Malware Classifications\")\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "provenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
